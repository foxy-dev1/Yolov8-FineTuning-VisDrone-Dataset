{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7438749,"sourceType":"datasetVersion","datasetId":4329460}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\ntrain_data = \"/kaggle/input/visdrone-dataset/VisDrone2019-DET-train/VisDrone2019-DET-train/images\"\ntest_data = \"/kaggle/input/visdrone-dataset/VisDrone2019-DET-val/VisDrone2019-DET-val/images\"\n\n\ntrain_labels = \"/kaggle/input/visdrone-dataset/VisDrone2019-DET-train/VisDrone2019-DET-train/annotations\"\ntest_labels = \"/kaggle/input/visdrone-dataset/VisDrone2019-DET-val/VisDrone2019-DET-val/annotations\"\n\nroot_dir = os.path.join(\"/kaggle/working/\",\"images\")\nos.makedirs(root_dir,exist_ok=True)\n\ntrain_dir = os.path.join(root_dir, \"train\")\nval_dir = os.path.join(root_dir, \"val\")\n\n\nlabel_root_dir = root_dir = os.path.join(\"/kaggle/working/\",\"labels\")\nos.makedirs(label_root_dir,exist_ok=True)\n\nlabel_train_dir = os.path.join(label_root_dir, \"train\")\nlabel_val_dir = os.path.join(label_root_dir, \"val\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:52:13.425762Z","iopub.execute_input":"2025-05-20T16:52:13.426054Z","iopub.status.idle":"2025-05-20T16:52:13.433772Z","shell.execute_reply.started":"2025-05-20T16:52:13.426030Z","shell.execute_reply":"2025-05-20T16:52:13.433254Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from PIL import Image\nfrom pathlib import Path\nfrom tqdm import tqdm\n\ndef convert_visdrone_to_yolo(annotations_path, images_path, output_label_path):\n    os.makedirs(output_label_path, exist_ok=True)\n\n    annotation_files = list(Path(annotations_path).glob(\"*.txt\"))\n    \n    for ann_file in tqdm(annotation_files, desc=f\"Converting {annotations_path}\"):\n        # Get corresponding image size\n        image_file = Path(images_path) / ann_file.with_suffix('.jpg').name\n        if not image_file.exists():\n            continue\n        img = Image.open(image_file)\n        w, h = img.size\n\n        lines = []\n        with open(ann_file, 'r') as f:\n            for row in f:\n                parts = row.strip().split(',')\n                if parts[4] == '0':  # ignored region\n                    continue\n                class_id = int(parts[5]) - 1\n                x, y, width, height = map(int, parts[:4])\n\n                # Convert to YOLO format\n                x_center = (x + width / 2) / w\n                y_center = (y + height / 2) / h\n                w_norm = width / w\n                h_norm = height / h\n\n                yolo_line = f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\"\n                lines.append(yolo_line)\n\n        # Write to YOLO label file\n        label_file_path = Path(output_label_path) / ann_file.name\n        with open(label_file_path, 'w') as out_file:\n            out_file.write('\\n'.join(lines))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:52:17.107796Z","iopub.execute_input":"2025-05-20T16:52:17.108372Z","iopub.status.idle":"2025-05-20T16:52:17.120113Z","shell.execute_reply.started":"2025-05-20T16:52:17.108351Z","shell.execute_reply":"2025-05-20T16:52:17.119629Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import shutil\n\nshutil.copytree(train_data,train_dir,dirs_exist_ok=True)\nshutil.copytree(test_data,val_dir,dirs_exist_ok=True)\nprint(\"train and val dirs copied\")\n\nconvert_visdrone_to_yolo(train_labels, train_data, label_train_dir)\nconvert_visdrone_to_yolo(test_labels, test_data, label_val_dir)\nprint(\"Converted annotations to YOLO format\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:52:19.924755Z","iopub.execute_input":"2025-05-20T16:52:19.924973Z","iopub.status.idle":"2025-05-20T16:55:01.322854Z","shell.execute_reply.started":"2025-05-20T16:52:19.924958Z","shell.execute_reply":"2025-05-20T16:55:01.322159Z"}},"outputs":[{"name":"stdout","text":"train and val dirs copied\n","output_type":"stream"},{"name":"stderr","text":"Converting /kaggle/input/visdrone-dataset/VisDrone2019-DET-train/VisDrone2019-DET-train/annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [01:05<00:00, 99.53it/s] \nConverting /kaggle/input/visdrone-dataset/VisDrone2019-DET-val/VisDrone2019-DET-val/annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:05<00:00, 102.53it/s]","output_type":"stream"},{"name":"stdout","text":"Converted annotations to YOLO format\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n\nfile_content = \"\"\"\n\npath: /kaggle/working/    # dataset root dir\ntrain: /kaggle/working/images/train    # train images \nval: /kaggle/working/images/val       # val images \n\n# Classes\nnames:\n  0: pedestrian\n  1: people\n  2: bicycle\n  3: car\n  4: van\n  5: truck\n  6: tricycle\n  7: awning-tricycle\n  8: bus\n  9: motor\n\n\n\"\"\"\n\nfile_name = \"VisDrone.yaml\"\n\nwith open(file_name,\"w\") as f:\n    f.write(file_content)\n\nprint(\"file saved\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:58:06.641102Z","iopub.execute_input":"2025-05-20T16:58:06.641373Z","iopub.status.idle":"2025-05-20T16:58:06.646931Z","shell.execute_reply.started":"2025-05-20T16:58:06.641351Z","shell.execute_reply":"2025-05-20T16:58:06.646308Z"}},"outputs":[{"name":"stdout","text":"file saved\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install -q ultralytics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:58:09.004763Z","iopub.execute_input":"2025-05-20T16:58:09.005314Z","iopub.status.idle":"2025-05-20T16:59:39.147055Z","shell.execute_reply.started":"2025-05-20T16:58:09.005293Z","shell.execute_reply":"2025-05-20T16:59:39.146270Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from ultralytics import YOLO\n\n\nmodel = YOLO(\"yolov8s.pt\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:59:39.148356Z","iopub.execute_input":"2025-05-20T16:59:39.149311Z","iopub.status.idle":"2025-05-20T16:59:47.274579Z","shell.execute_reply.started":"2025-05-20T16:59:39.149276Z","shell.execute_reply":"2025-05-20T16:59:47.273777Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 158MB/s] \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T17:17:53.641680Z","iopub.execute_input":"2025-05-20T17:17:53.642346Z","iopub.status.idle":"2025-05-20T17:17:53.649766Z","shell.execute_reply.started":"2025-05-20T17:17:53.642323Z","shell.execute_reply":"2025-05-20T17:17:53.649264Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model.train(data=\"/kaggle/working/VisDrone.yaml\",epochs=10,imgsz=640,workers=4,\n            batch=16,device=\"cuda\",name=\"yolov8_visdrone\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T17:18:06.751301Z","iopub.execute_input":"2025-05-20T17:18:06.751971Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.140 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/VisDrone.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_visdrone, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/yolov8_visdrone, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \nModel summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n\nTransferred 355/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 70.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3130.0Â±752.0 MB/s, size: 261.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/labels/train.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/images/train/0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/images/train/0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/images/train/9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/images/train/9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 430.0Â±210.9 MB/s, size: 131.6 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/labels/val.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/yolov8_visdrone/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/yolov8_visdrone\u001b[0m\nStarting training for 10 epochs...\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/10      10.6G      1.436      1.151     0.9439        787        640:  19%|â–ˆâ–‰        | 77/405 [00:24<01:37,  3.38it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}